**30｜HTTP/2：如何提升网络速度？**



> 对于HTTP1.1做了的大量优化，还是赶不上万维网的发展速度，在性能瓶颈下来探讨HTTP/2



#### HTTP1.1优化

1. 默认开启了持久化连接
2. 持久化连接带来了队头拥塞问题，所以还提供了管线化连接
3. HTTP默认支持每个域名6个TCP连接同时维护
4. 使用CDN实现域名分片机制

- 通过利用持久化连接减少了TCP建立销毁连接流程减少了RTT(Round Trip Time)

  ### 主要问题

  - 带宽(每秒最大能发送或者接收的字节数)利用率不高(核心问题)
    - 主要原因
      1. TCP慢启动，建立连接之后，TCP协议采用了一个很慢的速度发送数据，然后慢慢加快发送数据的速度，直到达到一个理想速度(汽车提速类比)，主要为了减少网络拥塞的策略，所以在加载关键资源文件的时候，本身就不大，慢启动比正常传输速度慢很多
      2. 同时开启多条TCP连接， 连接就会形成竟态，争夺固定的带宽，带宽不足的时候，就要减慢发送速度或者接收的速度，下载过程中的带宽不足各个TCP连接就会动态减慢接收数据的速度，TCP连接之间不能协商哪些关键资源优先下载，所以可能会影响关键资源的下载速度
      3. HTTP1.1队头拥塞问题 虽然持久化连接可以减少RTT开销时间，但是在共用的TCP管道中，每次也只能处理一个请求，当前请求没结束前，排队后面的请求只能处于等待挂起状态，队头阻塞使得数据不能并行请求，所以不利于浏览器优化

### HTTP2多路复用

- 一个域名只使用一个TCP长连接传输数据，这样整个页面资源下载过程只需要一次慢启动，避免多个TCP长连接导致竟态问题，其同时也实现了资源的并行请求，这样任何时候都可以将请求发送给服务器，不需要等待其他请求完成，这样也解决了队头拥塞的问题
- 多路复用可以将请求分成一帧一帧的数据去传输(分帧层)，好处是收到一个优先级别高的请求可以暂停之前的请求然后优先处理关键资源的请求
- 实现流程：HTTP/2 有多个请求同时进行，通过二进制分帧层进行传输，这样并行发送请求的数据通过带上ID进行拆分合并，并行接收时不会相互影响到数据的完整性，同时加入了可选项TLS
  1. 浏览器准备好请求数据，包括请求行和请求头等信息， POST信息还需要有请求体
  2. 数据经过二进制分帧层处理之后，转换为一个个带有ID编号的帧，通过协议栈将帧发送给服务器
  3. 服务器接收到所有帧之后，将所有相同ID的帧合并为一条完整的请求信息
  4. 服务器处理该请求，将处理的响应行和响应头和响应体分别传至二进制分帧层
  5. 二进制分帧层将这些响应数据转换为一个个带请求ID的帧，经过协议栈发送给服务器
- 对于HTTP版本只是传输的方式进行改变



### HTTP2 其他特性

- 可以设置请求的优先级，发送请求时通过标记上的优先级服务器可以优先处理
- 服务器推送，HTTP2可以直接将数据提前推送到浏览器
- 头部压缩 请求头和响应头压缩，数据压缩到原来的20%的话，传输效率肯定也大大提升



## summary

- 影响HTTP/1.1的主要因素是持久化连接带来的TCP慢启动和TCP连接之间的竟态问题，还有队头拥塞，通过HTTP2引入多路复用机制解决，多路复用主要是可以实现请求的并行发送接收和二进制分帧层实现的，二进制分帧层中的ID编号机制也可以实现资源的优先级和服务器推送，头部压缩等功能特性，性能大幅提升
- HTTP2在2015年真实发布，现在一些较大的网站也会部署HTTP2，使用HTTP2效率能提升20%~60%，所以可以放弃HTTP/1.1，拥抱HTTP/2

- TCP仍然会有数据包级别的对头阻塞问题。数据包如果一部分已经到达了，有一个失败传输(没有按顺序传输)，则会触发超时重传机制 ，因为TCP有这双向可靠的传输机制，数据没有全部接收到，同样数据不会返回给上层的应用层进行数据的处理。